{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabe-flomo/Python-Course/blob/main/Modules/3.%20Data%20structures%20and%20Methods/3.3%20Strings/string_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lFTePIUzy1z"
      },
      "source": [
        "# TASK 1\n",
        "Below is a dictionary with some movie data in it. Some of the movies have missing data and your job is to replace the missing data with `None`.\n",
        "\n",
        "***All missing data is represented as an empty string***\n",
        "\n",
        "## Example output \n",
        "```python\n",
        "# Original Dataset\n",
        "[\n",
        "    {\n",
        "        'Title': 'Star wars Episode 1',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Cleaned dataset\n",
        "[\n",
        "    {\n",
        "        'Title': 'Star wars Episode 1',\n",
        "        'Duration': None,\n",
        "        'Release Year': None\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tleo1v_zy10"
      },
      "outputs": [],
      "source": [
        "var = [\n",
        "    {\n",
        "        'Title': 'Star Wars Episode 1',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    },\n",
        "    {\n",
        "        'Title': 'Jungle Book',\n",
        "        'Duration': \"103\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Interstellar',\n",
        "        'Duration': \"150\",\n",
        "        'Release Year': \"2014\"\n",
        "    },{\n",
        "        'Title': '',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Star Wars Episode 2',\n",
        "        'Duration': \"126\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Toy story 4',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"2019\"\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-gSPwqzy11"
      },
      "source": [
        "# TASK 2\n",
        "You're given a list of phrases and you're asked to complete the following steps for each phrase in the list.\n",
        "\n",
        "* Replace all of the commas with empty strings\n",
        "* split the phrases and update the list to be the result of the split.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "# BEFORE\n",
        "[\n",
        "    'hello, world',\n",
        "    'hello, universe', \n",
        "    'hello, Gabe'\n",
        "]\n",
        "\n",
        "# AFTER\n",
        "[\n",
        "    ['hello', 'world'],\n",
        "    ['hello', 'universe'],\n",
        "    ['hello', 'Gabe']\n",
        "]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fNakBuDzy11"
      },
      "outputs": [],
      "source": [
        "var = ['If you are ill, you ought to see a doctor', \"When the snow stops falling, we'll shovel the driveway\", 'While I was eating, the cat scratched at the door']\n",
        "#TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x5Qccnzy12"
      },
      "source": [
        "# TASK 3\n",
        "Use the predefined `get_word` function to generate a list of 20 words. Then out of those 20 words, find all the words that contain repeating characters. For example, `book` has repeating characters because the letter `o` is followed by another `o`.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "original = ['growing',\n",
        " 'leafinesses',\n",
        " 'grivets',\n",
        " 'bigmouthed',\n",
        " 'militarizing',\n",
        " 'safenesses',\n",
        " 'credulousness'\n",
        "]\n",
        "\n",
        "repeats = [\n",
        "    'leafinesses',\n",
        "    'safenesses',\n",
        "    'credulousness'\n",
        "]\n",
        "\n",
        "print(\"There were 3 words with repeating characters\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlgKQuD3zy12"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "def get_word():\n",
        "    word = requests.get(\"https://random-word-api.herokuapp.com/word?number=20\").json()\n",
        "    return word\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usA6VI2fzy12"
      },
      "source": [
        "# TASK 4\n",
        "Using the same `get_word` function from the previous task, generate another 20 words. Then for each word, create a dictionary containing the count of each letter in the word and how many unique characters are in the word. Then add the dictionary to a list called `counts` and print out the list of dictionaries.\n",
        "\n",
        "## Example output\n",
        "```python \n",
        "words = [\n",
        "    'banana',\n",
        "    'apple',\n",
        "    'blueberry'\n",
        "]\n",
        "\n",
        "counts = [\n",
        "    {\n",
        "        \"b\": 1,\n",
        "        \"a\": 3,\n",
        "        \"n\":2,\n",
        "        'unique characters': 3\n",
        "    },\n",
        "    {\n",
        "        \"a\": 1,\n",
        "        \"p\":2,\n",
        "        \"l\": 1,\n",
        "        \"e\": 1,\n",
        "        'unique characters': 4 \n",
        "    },\n",
        "    {\n",
        "        \"b\": 2,\n",
        "        'l': 1,\n",
        "        'u': 1,\n",
        "        'e': 2,\n",
        "        'r': 2,\n",
        "        'y': 1,\n",
        "        \"unique characters\": 6\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFH2FiS9zy13"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huyrvoo0zy13"
      },
      "source": [
        "# TASK 5\n",
        "Below is a function that will return to you samples of transcripts from different podcasts. A common task in NLP is converting a section of text into a numerical representation for the computer to understand. Your task is to create a mapping that maps each unique word in the text to a value, then replace each word in the text with its corresponding value. \n",
        "\n",
        "## Example output\n",
        "```python\n",
        "text = \"This is some random text that needs to be encoded to numbers so that the computer can understand it\"\n",
        "\n",
        "mapping = {'text': '1',\n",
        " 'that': '2',\n",
        " 'it': '3',\n",
        " 'be': '4',\n",
        " 'encoded': '5',\n",
        " 'numbers': '6',\n",
        " 'can': '7',\n",
        " 'so': '8',\n",
        " 'is': '9',\n",
        " 'to': '10',\n",
        " 'computer': '11',\n",
        " 'understand': '12',\n",
        " 'random': '13',\n",
        " 'needs': '14',\n",
        " 'some': '15',\n",
        " 'This': '16',\n",
        " 'the': '17'}\n",
        "\n",
        " encoded_text = '16 9 15 13 1 2 14 10 4 5 10 6 8 2 17 11 7 12 3'\n",
        "```\n",
        "\n",
        "### Pseudo-code (optional to follow)\n",
        "* convert the text into a list called `tokens`\n",
        "* get a list of all the `unique_tokens`\n",
        "* create an empty dictionary called `mapping`\n",
        "* loop through the unique tokens and add the current token as the `key` in mapping and assign the value of the current iteration as the `value`.\n",
        "* loop through the *range of the length* of tokens and reassign the token at each index to the value that it's mapped to.\n",
        "* use the `join` method to convert the list of encoded tokens back into a string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-04NkjAzy14"
      },
      "outputs": [],
      "source": [
        "from random import randint, choice\n",
        "def get_sample_text():\n",
        "    urls = [\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_13.txt\",\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_16.txt\",\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_20.txt\"\n",
        "    ]\n",
        "    lower = randint(0, 100)\n",
        "    upper = randint(99, 2000)\n",
        "    url = choice(urls)\n",
        "    data = requests.get(url).text\n",
        "    data = data.replace(\"\\n\", \" \")\n",
        "    return data[lower:upper]\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToABokgdzy14"
      },
      "source": [
        "# TASK 6\n",
        "Use the `get_word` function from task 3 to generate another 20 words. Count how many words end with `ing`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG5mko5yzy14"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lthHk3Fszy14"
      },
      "source": [
        "# TASK 7\n",
        "Find all of the numeric strings in the list and find the sum and average of all the numbers.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "var = [\"1\", \"hello\", \"St\", \"5\", \"22\", \"not a number\", \"15\"]\n",
        "numbers = [1, 5, 22, 15]\n",
        "sum = 43\n",
        "avg = 10.75\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5UAat9xzy15"
      },
      "outputs": [],
      "source": [
        "def get_list():\n",
        "    words = get_word()\n",
        "    return [choice([str(randint(0,100)), choice(words)]) for _ in range(20)]\n",
        "\n",
        "var = get_list()\n",
        "\n",
        "#TODO "
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f1a916808f2d29f1a5fbd48aa1cb9129993ca703ecce713879d0cd946e898e32"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('legacy': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "string_tasks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}